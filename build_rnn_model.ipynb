{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from MusicRnnData import MusicRnnData\n",
    "\n",
    "# input parameters\n",
    "x_len = 50\n",
    "y_len = 1\n",
    "batch_size = 64\n",
    "# LSTM parameters\n",
    "num_layers = 2\n",
    "lstm_size = 128\n",
    "hidden_size = 128\n",
    "# training parameters\n",
    "learning_rate = 1e-1\n",
    "num_steps = 50000\n",
    "verbose = True\n",
    "display_interval = 500\n",
    "moving_avg_length = 100\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class MovingAverager(object):\n",
    "    def __init__(self, filter_length):\n",
    "        self.filter = deque([0 for _ in range(filter_length)])\n",
    "        \n",
    "    def insert(self, num):\n",
    "        self.filter.popleft()\n",
    "        self.filter.append(num)\n",
    "        \n",
    "    def average(self):\n",
    "        return sum(self.filter)/float(len(self.filter))\n",
    "    \n",
    "def build_lstm_stack(num_layers, lstm_size):\n",
    "    lstm_stack = [tf.contrib.rnn.BasicLSTMCell(lstm_size) for _ in range(num_layers)]\n",
    "    return tf.contrib.rnn.MultiRNNCell(lstm_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = ['a2002011001-e02.wav']\n",
    "music_data = MusicRnnData(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.placeholder(tf.float32, [batch_size, x_len])\n",
    "y = tf.placeholder(tf.float32, [batch_size, y_len])\n",
    "\n",
    "# RNN Cell\n",
    "lstm = build_lstm_stack(num_layers, lstm_size)\n",
    "# add dropout here\n",
    "\n",
    "# output layer\n",
    "output, states = tf.contrib.rnn.static_rnn(lstm, [x], dtype=tf.float32)\n",
    "fc_weights = tf.Variable(tf.random_normal([hidden_size, y_len]))\n",
    "fc_bias = tf.Variable(tf.random_normal([y_len]))\n",
    "\n",
    "y_ = tf.matmul(output[-1], fc_weights) + fc_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.nn.l2_loss(y_ - y)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, training loss: 0.568274\n",
      "step: 500, training loss: 0.164503\n",
      "moving average: 0.00732778\n",
      "step: 1000, training loss: 0.0714082\n",
      "moving average: 0.00804186\n",
      "step: 1500, training loss: 0.0640131\n",
      "moving average: 0.00868199\n",
      "step: 2000, training loss: 0.0973515\n",
      "moving average: 0.0096555\n",
      "step: 2500, training loss: 0.0471473\n",
      "moving average: 0.010127\n",
      "step: 3000, training loss: 0.119781\n",
      "moving average: 0.0113248\n",
      "step: 3500, training loss: 0.0698413\n",
      "moving average: 0.0120232\n",
      "step: 4000, training loss: 0.0580176\n",
      "moving average: 0.0126034\n",
      "step: 4500, training loss: 0.0680143\n",
      "moving average: 0.0132835\n",
      "step: 5000, training loss: 0.102312\n",
      "moving average: 0.0143066\n",
      "step: 5500, training loss: 0.0932612\n",
      "moving average: 0.0152392\n",
      "step: 6000, training loss: 0.0718006\n",
      "moving average: 0.0159573\n",
      "step: 6500, training loss: 0.0571865\n",
      "moving average: 0.0165291\n",
      "step: 7000, training loss: 0.12782\n",
      "moving average: 0.0178073\n",
      "step: 7500, training loss: 0.108801\n",
      "moving average: 0.0188953\n",
      "step: 8000, training loss: 0.0809633\n",
      "moving average: 0.019705\n",
      "step: 8500, training loss: 0.075425\n",
      "moving average: 0.0204592\n",
      "step: 9000, training loss: 0.0970301\n",
      "moving average: 0.0214295\n",
      "step: 9500, training loss: 0.0822488\n",
      "moving average: 0.022252\n",
      "step: 10000, training loss: 0.0553741\n",
      "moving average: 0.0228057\n",
      "step: 10500, training loss: 0.0906367\n",
      "moving average: 0.0237121\n",
      "step: 11000, training loss: 0.0469195\n",
      "moving average: 0.0241813\n",
      "step: 11500, training loss: 0.0848283\n",
      "moving average: 0.0250296\n",
      "step: 12000, training loss: 0.074971\n",
      "moving average: 0.0257793\n",
      "step: 12500, training loss: 0.0930894\n",
      "moving average: 0.0267102\n",
      "step: 13000, training loss: 0.0602403\n",
      "moving average: 0.0273126\n",
      "step: 13500, training loss: 0.108062\n",
      "moving average: 0.0283932\n",
      "step: 14000, training loss: 0.0824926\n",
      "moving average: 0.0292181\n",
      "step: 14500, training loss: 0.0717637\n",
      "moving average: 0.0299358\n",
      "step: 15000, training loss: 0.0696896\n",
      "moving average: 0.0306327\n",
      "step: 15500, training loss: 0.139586\n",
      "moving average: 0.0320285\n",
      "step: 16000, training loss: 0.0464278\n",
      "moving average: 0.0324928\n",
      "step: 16500, training loss: 0.0913878\n",
      "moving average: 0.0334067\n",
      "step: 17000, training loss: 0.0960826\n",
      "moving average: 0.0343675\n",
      "step: 17500, training loss: 0.0618091\n",
      "moving average: 0.0349856\n",
      "step: 18000, training loss: 0.115117\n",
      "moving average: 0.0361368\n",
      "step: 18500, training loss: 0.0244271\n",
      "moving average: 0.036381\n",
      "step: 19000, training loss: 0.0880791\n",
      "moving average: 0.0372618\n",
      "step: 19500, training loss: 0.128245\n",
      "moving average: 0.0385443\n",
      "step: 20000, training loss: 0.0660958\n",
      "moving average: 0.0392052\n",
      "step: 20500, training loss: 0.0843134\n",
      "moving average: 0.0400484\n",
      "step: 21000, training loss: 0.0498139\n",
      "moving average: 0.0405465\n",
      "step: 21500, training loss: 0.0866493\n",
      "moving average: 0.041413\n",
      "step: 22000, training loss: 0.1233\n",
      "moving average: 0.042646\n",
      "step: 22500, training loss: 0.443032\n",
      "moving average: 0.0470763\n",
      "step: 23000, training loss: 0.0893242\n",
      "moving average: 0.0479696\n",
      "step: 23500, training loss: 0.0599075\n",
      "moving average: 0.0485687\n",
      "step: 24000, training loss: 0.0815157\n",
      "moving average: 0.0493838\n",
      "step: 24500, training loss: 0.10264\n",
      "moving average: 0.0504102\n",
      "step: 25000, training loss: 0.0677104\n",
      "moving average: 0.0510873\n",
      "step: 25500, training loss: 0.0907414\n",
      "moving average: 0.0519947\n",
      "step: 26000, training loss: 0.0820972\n",
      "moving average: 0.0528157\n",
      "step: 26500, training loss: 0.0698315\n",
      "moving average: 0.053514\n",
      "step: 27000, training loss: 0.0900318\n",
      "moving average: 0.0544143\n",
      "step: 27500, training loss: 0.0902544\n",
      "moving average: 0.0553169\n",
      "step: 28000, training loss: 0.0764957\n",
      "moving average: 0.0560818\n",
      "step: 28500, training loss: 0.0564505\n",
      "moving average: 0.0566463\n",
      "step: 29000, training loss: 0.0689363\n",
      "moving average: 0.0573357\n",
      "step: 29500, training loss: 0.075395\n",
      "moving average: 0.0580897\n",
      "step: 30000, training loss: 0.0937821\n",
      "moving average: 0.0590275\n",
      "step: 30500, training loss: 0.0806892\n",
      "moving average: 0.0598344\n",
      "step: 31000, training loss: 0.108204\n",
      "moving average: 0.0609164\n",
      "step: 31500, training loss: 0.0788901\n",
      "moving average: 0.0617053\n",
      "step: 32000, training loss: 0.0854964\n",
      "moving average: 0.0625603\n",
      "step: 32500, training loss: 0.0751963\n",
      "moving average: 0.0633122\n",
      "step: 33000, training loss: 0.0735053\n",
      "moving average: 0.0640473\n",
      "step: 33500, training loss: 0.0685449\n",
      "moving average: 0.0647327\n",
      "step: 34000, training loss: 0.0668545\n",
      "moving average: 0.0654013\n",
      "step: 34500, training loss: 0.0721812\n",
      "moving average: 0.0661231\n",
      "step: 35000, training loss: 0.065704\n",
      "moving average: 0.0667801\n",
      "step: 35500, training loss: 0.102412\n",
      "moving average: 0.0678043\n",
      "step: 36000, training loss: 0.0833873\n",
      "moving average: 0.0686381\n",
      "step: 36500, training loss: 0.04595\n",
      "moving average: 0.0690976\n",
      "step: 37000, training loss: 0.0645394\n",
      "moving average: 0.069743\n",
      "step: 37500, training loss: 0.0440192\n",
      "moving average: 0.0701832\n",
      "step: 38000, training loss: 0.106812\n",
      "moving average: 0.0712513\n",
      "step: 38500, training loss: 0.0864177\n",
      "moving average: 0.0721155\n",
      "step: 39000, training loss: 0.0760207\n",
      "moving average: 0.0728757\n",
      "step: 39500, training loss: 0.0625038\n",
      "moving average: 0.0735008\n",
      "step: 40000, training loss: 0.0851129\n",
      "moving average: 0.0743519\n",
      "step: 40500, training loss: 0.0753666\n",
      "moving average: 0.0751055\n",
      "step: 41000, training loss: 0.0658264\n",
      "moving average: 0.0757638\n",
      "step: 41500, training loss: 0.0674448\n",
      "moving average: 0.0764383\n",
      "step: 42000, training loss: 0.133335\n",
      "moving average: 0.0777716\n",
      "step: 42500, training loss: 0.0928339\n",
      "moving average: 0.0786999\n",
      "step: 43000, training loss: 0.0844598\n",
      "moving average: 0.0795445\n",
      "step: 43500, training loss: 0.0520294\n",
      "moving average: 0.0800648\n",
      "step: 44000, training loss: 0.0579349\n",
      "moving average: 0.0806442\n",
      "step: 44500, training loss: 0.0861995\n",
      "moving average: 0.0815062\n",
      "step: 45000, training loss: 0.114526\n",
      "moving average: 0.0826514\n",
      "step: 45500, training loss: 0.0782876\n",
      "moving average: 0.0834343\n",
      "step: 46000, training loss: 0.0532817\n",
      "moving average: 0.0839671\n",
      "step: 46500, training loss: 0.0647419\n",
      "moving average: 0.0846146\n",
      "step: 47000, training loss: 0.0946889\n",
      "moving average: 0.0855614\n",
      "step: 47500, training loss: 0.0686953\n",
      "moving average: 0.0862484\n",
      "step: 48000, training loss: 0.0804207\n",
      "moving average: 0.0870526\n",
      "step: 48500, training loss: 0.0816924\n",
      "moving average: 0.0878695\n",
      "step: 49000, training loss: 0.0410586\n",
      "moving average: 0.0882801\n",
      "step: 49500, training loss: 0.0753261\n",
      "moving average: 0.0890334\n"
     ]
    }
   ],
   "source": [
    "moving_avg = MovingAverager(moving_avg_length)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_steps):\n",
    "        x_batch, y_batch = music_data.batch(x_len, y_len, batch_size)\n",
    "        _, loss = sess.run([optimizer, cost], feed_dict={x: x_batch, y: y_batch})\n",
    "\n",
    "        # print progress\n",
    "        if verbose and (i % display_interval == 0):\n",
    "            print('step: %d, training loss: %g' % (i, loss))\n",
    "            \n",
    "            # moving averager\n",
    "            moving_avg.insert(loss)\n",
    "            if i > moving_avg_length:\n",
    "                print('moving average: %g' % (moving_avg.average()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
