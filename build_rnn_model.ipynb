{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "from MusicRnnData import MusicRnnData\n",
    "\n",
    "# input parameters\n",
    "x_len = 10\n",
    "y_len = 1\n",
    "batch_size = 32\n",
    "# LSTM parameters\n",
    "num_layers = 1\n",
    "lstm_size = 8\n",
    "hidden_size = 8\n",
    "# training parameters\n",
    "dropout_prob = 0.5\n",
    "learning_rate = 1e-1\n",
    "num_steps = 50000\n",
    "verbose = True\n",
    "display_interval = 500\n",
    "moving_avg_length = 100\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class MovingAverager(object):\n",
    "    def __init__(self, filter_length):\n",
    "        self.filter = deque([0 for _ in range(filter_length)])\n",
    "        \n",
    "    def insert(self, num):\n",
    "        self.filter.popleft()\n",
    "        self.filter.append(num)\n",
    "        \n",
    "    def average(self):\n",
    "        return sum(self.filter)/float(len(self.filter))\n",
    "    \n",
    "def build_lstm_stack(num_layers, lstm_size, dropout_prob=1.0):\n",
    "    def lstm_layer(lstm_size, dropout_prob=1.0):\n",
    "        lstm_layer = tf.contrib.rnn.BasicLSTMCell(lstm_size, forget_bias=0.0)\n",
    "        return tf.contrib.rnn.DropoutWrapper(lstm_layer, output_keep_prob=dropout_prob)\n",
    "    \n",
    "    lstm_stack = [lstm_layer(lstm_size, dropout_prob=dropout_prob) for _ in range(num_layers)]\n",
    "    return tf.contrib.rnn.MultiRNNCell(lstm_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filelist = ['a2002011001-e02.wav']\n",
    "filelist = ['sine.wav']\n",
    "music_data = MusicRnnData(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.placeholder(tf.float32, [batch_size, x_len])\n",
    "y = tf.placeholder(tf.float32, [batch_size, y_len])\n",
    "\n",
    "# RNN Cell\n",
    "lstm = build_lstm_stack(num_layers, lstm_size, dropout_prob=dropout_prob)\n",
    "# add dropout here\n",
    "\n",
    "# output layer\n",
    "output, states = tf.contrib.rnn.static_rnn(lstm, [x], dtype=tf.float32)\n",
    "fc_weights = tf.Variable(tf.random_normal([hidden_size, y_len]))\n",
    "fc_bias = tf.Variable(tf.random_normal([y_len]))\n",
    "\n",
    "y_ = tf.matmul(output[-1], fc_weights) + fc_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cost = tf.divide(tf.nn.l2_loss(y_ - y), y_len)\n",
    "cost = tf.reduce_mean(tf.squared_difference(y_, y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set summary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_save = './Logs'\n",
    "\n",
    "# define summary for tensorboard\n",
    "tf.summary.scalar('loss', cost)\n",
    "tf.summary.histogram('fc_weights', fc_weights)\n",
    "tf.summary.histogram('fc_bias', fc_bias)\n",
    "tf.summary.histogram('lstm_output', output)\n",
    "tf.summary.histogram('prediction', y_)\n",
    "summary_merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize moving averager for loss\n",
    "if verbose:\n",
    "    moving_avg = MovingAverager(moving_avg_length)\n",
    "\n",
    "# create session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# define saver\n",
    "if os.path.exists(dir_save):\n",
    "    shutil.rmtree(dir_save)\n",
    "train_writer = tf.summary.FileWriter(dir_save, sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# and begin\n",
    "for i in range(num_steps):\n",
    "    x_batch, y_batch = music_data.batch(x_len, y_len, batch_size)\n",
    "    _, loss, summary = sess.run([optimizer, cost, summary_merged], feed_dict={x: x_batch, y: y_batch})\n",
    "    \n",
    "    train_writer.add_summary(summary, i)\n",
    "\n",
    "    if verbose:\n",
    "        moving_avg.insert(loss)\n",
    "        # print progress\n",
    "        if (i % display_interval == 0):\n",
    "            print('step: %d, training loss: %g' % (i, loss))\n",
    "\n",
    "            if i > moving_avg_length:\n",
    "                print('moving average loss: %g' % (moving_avg.average()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "display_interval = 1000\n",
    "\n",
    "original = music_data.convert_to_wav(music_data.tracks[0])\n",
    "orig_len = original.shape[0]\n",
    "\n",
    "prediction = original[0:x_len]\n",
    "num_predictions = int((orig_len-x_len)/y_len)\n",
    "x_batch = prediction\n",
    "for i in range(num_predictions):\n",
    "    feed_pred = np.expand_dims(x_batch, axis=0)\n",
    "    feed_pred = np.repeat(feed_pred, batch_size, axis=0)\n",
    "    new_y = sess.run([y_], feed_dict={x: feed_pred, y: y_batch})[0][0,:]\n",
    "    prediction = np.append(prediction, new_y, axis=0)\n",
    "    x_batch = np.append(x_batch[y_len:], new_y, axis=0)\n",
    "    \n",
    "    if (i % display_interval == 0):\n",
    "        print('Iteration: %d, len(prediction) = %g' % (i, len(prediction)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "converted = music_data.convert_to_wav(prediction)\n",
    "pred_len = converted.shape[0]\n",
    "x_orig = np.linspace(0, orig_len/music_data.sample_rate, orig_len)\n",
    "x_conv = np.linspace(0, pred_len/music_data.sample_rate, pred_len)\n",
    "plt.subplot(211)\n",
    "plt.plot(x_orig[0:300], original[0:300])\n",
    "plt.subplot(212)\n",
    "plt.plot(x_conv[0:300], converted[0:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
