{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "from MusicRnnData import MusicRnnData\n",
    "\n",
    "# input parameters\n",
    "x_len = 10\n",
    "y_len = 1\n",
    "batch_size = 1\n",
    "# LSTM parameters\n",
    "num_layers = 1\n",
    "lstm_size = 8\n",
    "hidden_size = 8\n",
    "# training parameters\n",
    "dropout_prob = 0.5\n",
    "learning_rate = 1e-1\n",
    "num_steps = 50000\n",
    "verbose = True\n",
    "display_interval = 500\n",
    "moving_avg_length = 100\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class MovingAverager(object):\n",
    "    def __init__(self, filter_length):\n",
    "        self.filter = deque([0 for _ in range(filter_length)])\n",
    "        \n",
    "    def insert(self, num):\n",
    "        self.filter.popleft()\n",
    "        self.filter.append(num)\n",
    "        \n",
    "    def average(self):\n",
    "        return sum(self.filter)/float(len(self.filter))\n",
    "    \n",
    "def build_lstm_stack(num_layers, lstm_size, dropout_prob=1.0):\n",
    "    def lstm_layer(lstm_size, dropout_prob=1.0):\n",
    "        lstm_layer = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        return tf.contrib.rnn.DropoutWrapper(lstm_layer, output_keep_prob=dropout_prob)\n",
    "    \n",
    "    lstm_stack = [lstm_layer(lstm_size, dropout_prob=dropout_prob) for _ in range(num_layers)]\n",
    "    return tf.contrib.rnn.MultiRNNCell(lstm_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filelist = ['a2002011001-e02.wav']\n",
    "filelist = ['sine.wav']\n",
    "music_data = MusicRnnData(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.placeholder(tf.float32, [batch_size, x_len])\n",
    "y = tf.placeholder(tf.float32, [batch_size, y_len])\n",
    "\n",
    "# RNN Cell\n",
    "lstm = build_lstm_stack(num_layers, lstm_size, dropout_prob=dropout_prob)\n",
    "# add dropout here\n",
    "\n",
    "# output layer\n",
    "output, states = tf.contrib.rnn.static_rnn(lstm, [x], dtype=tf.float32)\n",
    "fc_weights = tf.Variable(tf.random_normal([hidden_size, y_len]))\n",
    "fc_bias = tf.Variable(tf.random_normal([y_len]))\n",
    "\n",
    "y_ = tf.matmul(output[-1], fc_weights) + fc_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cost = tf.divide(tf.nn.l2_loss(y_ - y), y_len)\n",
    "cost = tf.reduce_mean(tf.squared_difference(y_, y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set summary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_save = './Logs'\n",
    "\n",
    "# define summary for tensorboard\n",
    "tf.summary.scalar('learning_rate', cost)\n",
    "summary_merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, training loss: 0.999412\n",
      "step: 500, training loss: 0.074743\n",
      "moving average loss: 0.100703\n",
      "step: 1000, training loss: 0.233639\n",
      "moving average loss: 0.0828682\n",
      "step: 1500, training loss: 0.0200707\n",
      "moving average loss: 0.0711575\n",
      "step: 2000, training loss: 0.0170109\n",
      "moving average loss: 0.0822004\n",
      "step: 2500, training loss: 0.00715887\n",
      "moving average loss: 0.0721346\n",
      "step: 3000, training loss: 0.0825668\n",
      "moving average loss: 0.0610811\n",
      "step: 3500, training loss: 0.000798302\n",
      "moving average loss: 0.0620597\n",
      "step: 4000, training loss: 0.101032\n",
      "moving average loss: 0.0774145\n",
      "step: 4500, training loss: 0.000439913\n",
      "moving average loss: 0.0852644\n",
      "step: 5000, training loss: 0.00661538\n",
      "moving average loss: 0.0668656\n",
      "step: 5500, training loss: 0.220353\n",
      "moving average loss: 0.0542021\n",
      "step: 6000, training loss: 0.0232836\n",
      "moving average loss: 0.0703216\n",
      "step: 6500, training loss: 0.0873569\n",
      "moving average loss: 0.0733865\n",
      "step: 7000, training loss: 0.0620765\n",
      "moving average loss: 0.088769\n",
      "step: 7500, training loss: 0.0156927\n",
      "moving average loss: 0.0735674\n",
      "step: 8000, training loss: 0.261521\n",
      "moving average loss: 0.106422\n",
      "step: 8500, training loss: 0.0695935\n",
      "moving average loss: 0.0591046\n",
      "step: 9000, training loss: 0.0938883\n",
      "moving average loss: 0.0931378\n",
      "step: 9500, training loss: 0.130799\n",
      "moving average loss: 0.0712606\n",
      "step: 10000, training loss: 0.0929154\n",
      "moving average loss: 0.0695549\n",
      "step: 10500, training loss: 0.0656134\n",
      "moving average loss: 0.0564744\n",
      "step: 11000, training loss: 0.0232874\n",
      "moving average loss: 0.0633632\n",
      "step: 11500, training loss: 0.11508\n",
      "moving average loss: 0.0756295\n",
      "step: 12000, training loss: 0.00524044\n",
      "moving average loss: 0.113845\n",
      "step: 12500, training loss: 0.0426331\n",
      "moving average loss: 0.0579564\n",
      "step: 13000, training loss: 0.00241276\n",
      "moving average loss: 0.0561044\n",
      "step: 13500, training loss: 0.0170837\n",
      "moving average loss: 0.0869269\n",
      "step: 14000, training loss: 0.130964\n",
      "moving average loss: 0.0952059\n",
      "step: 14500, training loss: 0.000678117\n",
      "moving average loss: 0.0642727\n",
      "step: 15000, training loss: 0.112214\n",
      "moving average loss: 0.0704283\n",
      "step: 15500, training loss: 0.0314256\n",
      "moving average loss: 0.0538618\n",
      "step: 16000, training loss: 0.00162421\n",
      "moving average loss: 0.078018\n",
      "step: 16500, training loss: 0.010998\n",
      "moving average loss: 0.057003\n",
      "step: 17000, training loss: 0.0150456\n",
      "moving average loss: 0.0477472\n",
      "step: 17500, training loss: 0.145422\n",
      "moving average loss: 0.0568458\n",
      "step: 18000, training loss: 0.0197556\n",
      "moving average loss: 0.0699094\n",
      "step: 18500, training loss: 0.0583732\n",
      "moving average loss: 0.0548258\n",
      "step: 19000, training loss: 0.19602\n",
      "moving average loss: 0.0564153\n",
      "step: 19500, training loss: 0.0184185\n",
      "moving average loss: 0.0650929\n",
      "step: 20000, training loss: 0.0140955\n",
      "moving average loss: 0.0526337\n",
      "step: 20500, training loss: 0.0238493\n",
      "moving average loss: 0.0523935\n",
      "step: 21000, training loss: 0.0878266\n",
      "moving average loss: 0.0581259\n",
      "step: 21500, training loss: 0.0389621\n",
      "moving average loss: 0.0528818\n",
      "step: 22000, training loss: 0.00717964\n",
      "moving average loss: 0.0664402\n",
      "step: 22500, training loss: 0.0414733\n",
      "moving average loss: 0.0835268\n",
      "step: 23000, training loss: 0.0565627\n",
      "moving average loss: 0.0796607\n",
      "step: 23500, training loss: 0.58211\n",
      "moving average loss: 0.073848\n",
      "step: 24000, training loss: 0.0500136\n",
      "moving average loss: 0.056147\n",
      "step: 24500, training loss: 0.184411\n",
      "moving average loss: 0.0755791\n",
      "step: 25000, training loss: 0.0103479\n",
      "moving average loss: 0.0597951\n",
      "step: 25500, training loss: 0.0532397\n",
      "moving average loss: 0.0607599\n",
      "step: 26000, training loss: 0.0167722\n",
      "moving average loss: 0.0761736\n",
      "step: 26500, training loss: 0.247374\n",
      "moving average loss: 0.0663998\n",
      "step: 27000, training loss: 0.00295182\n",
      "moving average loss: 0.104587\n",
      "step: 27500, training loss: 0.00751681\n",
      "moving average loss: 0.0787484\n",
      "step: 28000, training loss: 0.00219615\n",
      "moving average loss: 0.070491\n",
      "step: 28500, training loss: 0.00398405\n",
      "moving average loss: 0.096534\n",
      "step: 29000, training loss: 5.63797e-06\n",
      "moving average loss: 0.0975922\n",
      "step: 29500, training loss: 0.0720597\n",
      "moving average loss: 0.0759293\n",
      "step: 30000, training loss: 0.0142366\n",
      "moving average loss: 0.0635672\n",
      "step: 30500, training loss: 0.00383243\n",
      "moving average loss: 0.0433144\n",
      "step: 31000, training loss: 0.000791911\n",
      "moving average loss: 0.0667296\n",
      "step: 31500, training loss: 0.04485\n",
      "moving average loss: 0.0462914\n",
      "step: 32000, training loss: 0.0385752\n",
      "moving average loss: 0.0661264\n",
      "step: 32500, training loss: 0.0524679\n",
      "moving average loss: 0.0528064\n",
      "step: 33000, training loss: 0.00443745\n",
      "moving average loss: 0.0644988\n",
      "step: 33500, training loss: 0.00108817\n",
      "moving average loss: 0.0969107\n",
      "step: 34000, training loss: 0.0145151\n",
      "moving average loss: 0.0707701\n",
      "step: 34500, training loss: 0.00033851\n",
      "moving average loss: 0.0418996\n",
      "step: 35000, training loss: 0.0476558\n",
      "moving average loss: 0.0725754\n",
      "step: 35500, training loss: 0.0711124\n",
      "moving average loss: 0.0655126\n",
      "step: 36000, training loss: 0.0310883\n",
      "moving average loss: 0.0504799\n",
      "step: 36500, training loss: 0.00631553\n",
      "moving average loss: 0.0950602\n",
      "step: 37000, training loss: 0.00406232\n",
      "moving average loss: 0.0741558\n",
      "step: 37500, training loss: 0.0547554\n",
      "moving average loss: 0.0742118\n",
      "step: 38000, training loss: 0.0038162\n",
      "moving average loss: 0.101309\n",
      "step: 38500, training loss: 0.0378555\n",
      "moving average loss: 0.0606915\n",
      "step: 39000, training loss: 0.0903385\n",
      "moving average loss: 0.141968\n",
      "step: 39500, training loss: 0.0581449\n",
      "moving average loss: 0.0687789\n",
      "step: 40000, training loss: 0.00157193\n",
      "moving average loss: 0.0889921\n",
      "step: 40500, training loss: 0.0319201\n",
      "moving average loss: 0.0793391\n",
      "step: 41000, training loss: 0.00213105\n",
      "moving average loss: 0.0747203\n",
      "step: 41500, training loss: 0.00109518\n",
      "moving average loss: 0.0649778\n",
      "step: 42000, training loss: 0.413262\n",
      "moving average loss: 0.0658987\n",
      "step: 42500, training loss: 0.0207231\n",
      "moving average loss: 0.0556201\n",
      "step: 43000, training loss: 0.00462409\n",
      "moving average loss: 0.0840581\n",
      "step: 43500, training loss: 0.0361223\n",
      "moving average loss: 0.080572\n",
      "step: 44000, training loss: 0.00262338\n",
      "moving average loss: 0.0648172\n",
      "step: 44500, training loss: 0.154271\n",
      "moving average loss: 0.0521842\n",
      "step: 45000, training loss: 0.00705249\n",
      "moving average loss: 0.0909521\n",
      "step: 45500, training loss: 0.00848317\n",
      "moving average loss: 0.0684679\n",
      "step: 46000, training loss: 0.214958\n",
      "moving average loss: 0.0543235\n",
      "step: 46500, training loss: 0.130051\n",
      "moving average loss: 0.0826426\n",
      "step: 47000, training loss: 0.219523\n",
      "moving average loss: 0.101072\n",
      "step: 47500, training loss: 0.0113275\n",
      "moving average loss: 0.0819739\n",
      "step: 48000, training loss: 0.0420853\n",
      "moving average loss: 0.0938534\n",
      "step: 48500, training loss: 0.0963687\n",
      "moving average loss: 0.0863775\n",
      "step: 49000, training loss: 0.119003\n",
      "moving average loss: 0.063157\n",
      "step: 49500, training loss: 0.0206447\n",
      "moving average loss: 0.0715611\n"
     ]
    }
   ],
   "source": [
    "# initialize moving averager for loss\n",
    "if verbose:\n",
    "    moving_avg = MovingAverager(moving_avg_length)\n",
    "\n",
    "# create session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# define saver\n",
    "if os.path.exists(dir_save):\n",
    "    shutil.rmtree(dir_save)\n",
    "train_writer = tf.summary.FileWriter(dir_save, sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# and begin\n",
    "for i in range(num_steps):\n",
    "    x_batch, y_batch = music_data.batch(x_len, y_len, batch_size)\n",
    "    _, loss, summary = sess.run([optimizer, cost, summary_merged], feed_dict={x: x_batch, y: y_batch})\n",
    "    \n",
    "    train_writer.add_summary(summary, i)\n",
    "\n",
    "    if verbose:\n",
    "        moving_avg.insert(loss)\n",
    "        # print progress\n",
    "        if (i % display_interval == 0):\n",
    "            print('step: %d, training loss: %g' % (i, loss))\n",
    "\n",
    "            if i > moving_avg_length:\n",
    "                print('moving average loss: %g' % (moving_avg.average()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "display_interval = 1000\n",
    "\n",
    "original = music_data.convert_to_wav(music_data.tracks[0])\n",
    "orig_len = original.shape[0]\n",
    "\n",
    "prediction = original[0:x_len]\n",
    "num_predictions = int((orig_len-x_len)/y_len)\n",
    "x_batch = prediction\n",
    "for i in range(num_predictions):\n",
    "    feed_pred = np.expand_dims(x_batch, axis=0)\n",
    "    feed_pred = np.repeat(feed_pred, batch_size, axis=0)\n",
    "    new_y = sess.run([y_], feed_dict={x: feed_pred, y: y_batch})[0][0,:]\n",
    "    prediction = np.append(prediction, new_y, axis=0)\n",
    "    x_batch = np.append(x_batch[y_len:], new_y, axis=0)\n",
    "    \n",
    "    if (i % display_interval == 0):\n",
    "        print('Iteration: %d, len(prediction) = %g' % (i, len(prediction)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "converted = music_data.convert_to_wav(prediction)\n",
    "pred_len = converted.shape[0]\n",
    "x_orig = np.linspace(0, orig_len/music_data.sample_rate, orig_len)\n",
    "x_conv = np.linspace(0, pred_len/music_data.sample_rate, pred_len)\n",
    "plt.subplot(211)\n",
    "plt.plot(x_orig[0:300], original[0:300])\n",
    "plt.subplot(212)\n",
    "plt.plot(x_conv[0:300], converted[0:300])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
