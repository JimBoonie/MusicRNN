{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil, time, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from MusicData import MusicData\n",
    "\n",
    "# input parameters\n",
    "x_len = 80\n",
    "y_len = 40\n",
    "batch_size = 32\n",
    "n_samples = 4096\n",
    "# LSTM parameters\n",
    "num_layers = 2\n",
    "lstm_size = 50\n",
    "dropout_prob = 0.2\n",
    "# training parameters\n",
    "num_epochs = 100\n",
    "epoch_size = 4096\n",
    "verbose = True\n",
    "display_interval = 500\n",
    "moving_avg_length = 100\n",
    "learn_rate = 0.001\n",
    "momentum = 0.8\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 44100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filelist = ['a2002011001-e02.wav']\n",
    "filelist = ['sine.wav']\n",
    "music_data = MusicData(filelist, x_len, y_len)\n",
    "x_ex, y_ex = music_data.data[0]['x'], music_data.data[0]['y']\n",
    "\n",
    "print('Sample rate: {}'.format(music_data.sample_rate))\n",
    "x_duration = music_data.sample_rate * len(x_ex)\n",
    "x = np.linspace(0, x_duration, len(x_ex), endpoint=False)\n",
    "y_duration = music_data.sample_rate * len(y_ex) + x_duration\n",
    "y = np.linspace(x_duration, y_duration, len(y_ex), endpoint=False)\n",
    "\n",
    "plt.plot(x, x_ex, 'b')\n",
    "plt.plot(y, y_ex, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = ['train']\n",
    "dataset = {'train': music_data}\n",
    "from torch.utils.data.sampler import RandomSampler, BatchSampler\n",
    "samplers = {x: BatchSampler(sampler=RandomSampler(dataset[x]), batch_size=batch_size, drop_last=True)\n",
    "            for x in phases}\n",
    "dataloader = {x: DataLoader(dataset[x], num_workers=4, batch_sampler=samplers[x])\n",
    "              for x in phases}\n",
    "dataset_sizes = {'train': len(music_data.data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, x_len, y_len, num_layers=1, hidden_nodes=50, dropout=0.0, batch_size=batch_size):\n",
    "        super().__init__()\n",
    "        self.x_len = x_len\n",
    "        self.y_len = y_len\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "                \n",
    "        # define net parameters\n",
    "        self.rnn = nn.LSTM(x_len, hidden_nodes, num_layers=num_layers, dropout=dropout)\n",
    "        self.n_hidden_nodes = hidden_nodes\n",
    "        self.ln1 = nn.Linear(hidden_nodes, y_len)\n",
    "        \n",
    "    def init_hidden(self, hidden_nodes):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, hidden_nodes),\n",
    "                torch.zeros(self.num_layers, self.batch_size, hidden_nodes))\n",
    "        \n",
    "    def forward(self, x): \n",
    "        self.hidden = self.init_hidden(self.n_hidden_nodes)\n",
    "        x, self.hidden = self.rnn(x, self.hidden)\n",
    "        x = self.ln1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "rnn_model = MusicRNN(x_len, y_len, num_layers=num_layers, hidden_nodes=lstm_size, dropout=dropout_prob, \n",
    "                     batch_size=batch_size)\n",
    "\n",
    "rnn_model = rnn_model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.RMSprop(rnn_model.parameters(), lr=learn_rate, momentum=momentum)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, \n",
    "                phases, dataset_sizes, device=None, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    retain = True\n",
    "    for epoch in range(num_epochs):\n",
    "        # display epoch\n",
    "        print('Epoch {} / {}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            # reset loss for current phase and epoch\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = torch.unsqueeze(inputs, 0).to(device)\n",
    "                labels = torch.unsqueeze(labels, 0).to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # track history only during training phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(1)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        print()\n",
    "        \n",
    "#     time_elapsed = time.time() - since\n",
    "#     print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "#         time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "    \n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 99\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "\n",
      "Epoch 1 / 99\n",
      "----------\n",
      "train Loss: 0.0023\n",
      "\n",
      "Epoch 2 / 99\n",
      "----------\n",
      "train Loss: 0.0017\n",
      "\n",
      "Epoch 3 / 99\n",
      "----------\n",
      "train Loss: 0.0014\n",
      "\n",
      "Epoch 4 / 99\n",
      "----------\n",
      "train Loss: 0.0012\n",
      "\n",
      "Epoch 5 / 99\n",
      "----------\n",
      "train Loss: 0.0011\n",
      "\n",
      "Epoch 6 / 99\n",
      "----------\n",
      "train Loss: 0.0010\n",
      "\n",
      "Epoch 7 / 99\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "\n",
      "Epoch 8 / 99\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "\n",
      "Epoch 9 / 99\n",
      "----------\n",
      "train Loss: 0.0009\n",
      "\n",
      "Epoch 10 / 99\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "\n",
      "Epoch 11 / 99\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "\n",
      "Epoch 12 / 99\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "\n",
      "Epoch 13 / 99\n",
      "----------\n",
      "train Loss: 0.0008\n",
      "\n",
      "Epoch 14 / 99\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "\n",
      "Epoch 15 / 99\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "\n",
      "Epoch 16 / 99\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "\n",
      "Epoch 17 / 99\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "\n",
      "Epoch 18 / 99\n",
      "----------\n",
      "train Loss: 0.0006\n",
      "\n",
      "Epoch 19 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 20 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 21 / 99\n",
      "----------\n",
      "train Loss: 0.0007\n",
      "\n",
      "Epoch 22 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 23 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 24 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 25 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 26 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 27 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 28 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 29 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 30 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 31 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 32 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 33 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 34 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 35 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 36 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 37 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 38 / 99\n",
      "----------\n",
      "train Loss: 0.0005\n",
      "\n",
      "Epoch 39 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 40 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 41 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 42 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 43 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 44 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 45 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 46 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 47 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 48 / 99\n",
      "----------\n",
      "train Loss: 0.0004\n",
      "\n",
      "Epoch 49 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 50 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 51 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 52 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 53 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 54 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 55 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 56 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 57 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 58 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 59 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 60 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 61 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 62 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 63 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 64 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 65 / 99\n",
      "----------\n",
      "train Loss: 0.0003\n",
      "\n",
      "Epoch 66 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 67 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 68 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 69 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 70 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 71 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 72 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 73 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 74 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 75 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 76 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 77 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 78 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 79 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 80 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 81 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 82 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 83 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 84 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 85 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 86 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 87 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 88 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 89 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 90 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 91 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 92 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 93 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 94 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 95 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 96 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 97 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 98 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n",
      "Epoch 99 / 99\n",
      "----------\n",
      "train Loss: 0.0002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_model = train_model(rnn_model, dataloader, criterion, optimizer, scheduler, \n",
    "                        phases, dataset_sizes, device=device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, x_len, y_len, num_layers=1, hidden_nodes=[50], dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.x_len = x_len\n",
    "        self.y_len = y_len\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_nodes = {}\n",
    "        for i, h_n in enumerate(hidden_nodes):\n",
    "            self.hidden_nodes['rnn{}'.format(i)] = self.init_hidden(h_n)\n",
    "        self.dropout = dropout\n",
    "                \n",
    "        # define net parameters\n",
    "        self.net = {}\n",
    "        for i, hl in enumerate(hidden_nodes):\n",
    "            if i == 0:\n",
    "                layer_in = x_len\n",
    "                \n",
    "            self.net['rnn{}'.format(i + 1)] = nn.LSTM(layer_in, hl, num_layers=1, dropout=dropout)\n",
    "            layer_in = hl\n",
    "            \n",
    "        self.ln1 = nn.Linear()\n",
    "        \n",
    "    def init_hidden(self, hidden_nodes):\n",
    "        return (torch.zeros(1, 1, hidden_nodes),\n",
    "                torch.zeros(1, 1, hidden_nodes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x, self.hidden = self.net['rnn{}'.format(i + 1)](x, self.hidden)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PyTorchSIIM]",
   "language": "python",
   "name": "conda-env-PyTorchSIIM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
