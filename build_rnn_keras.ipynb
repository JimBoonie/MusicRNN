{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "from MusicRnnData import MusicRnnData\n",
    "\n",
    "# input parameters\n",
    "x_len = 80\n",
    "y_len = 40\n",
    "batch_size = 32\n",
    "n_samples = 4096\n",
    "# LSTM parameters\n",
    "num_layers = 2\n",
    "lstm_size = [50, 100]\n",
    "# training parameters\n",
    "dropout_prob = 0.2\n",
    "num_epochs = 100\n",
    "epoch_size = 4096\n",
    "verbose = True\n",
    "display_interval = 500\n",
    "moving_avg_length = 100\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filelist = ['a2002011001-e02.wav']\n",
    "filelist = ['sine.wav']\n",
    "music_data = MusicRnnData(filelist)\n",
    "x_train, y_train = music_data.batch(x_len, y_len, n_samples)\n",
    "\n",
    "# reshape to be (samples, timesteps, features)\n",
    "x_train = np.reshape(x_train, (n_samples, x_len, 1))\n",
    "y_train = np.reshape(y_train, (n_samples, y_len))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(x_len, lstm_size, dropout_prob):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_size[0], input_shape=(x_len, 1), return_sequences=True))\n",
    "    model.add(Dropout(dropout_prob))\n",
    "    model.add(LSTM(lstm_size[1], return_sequences=False))\n",
    "    model.add(Dropout(dropout_prob))\n",
    "    model.add(Dense(units=y_len))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "model = build_model(x_len, lstm_size, dropout_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "display_interval = 1000\n",
    "\n",
    "original = music_data.tracks[0]\n",
    "orig_len = original.shape[0]\n",
    "\n",
    "prediction = original[0:x_len]\n",
    "num_predictions = int((orig_len-x_len)/y_len)\n",
    "x_batch = prediction\n",
    "for i in range(num_predictions):\n",
    "    feed_pred = np.reshape(x_batch, (1, x_len, 1))\n",
    "    feed_pred = np.repeat(feed_pred, batch_size, axis=0)\n",
    "    new_y = model.predict(feed_pred, batch_size=batch_size)[0,:]\n",
    "    prediction = np.append(prediction, new_y, axis=0)\n",
    "    x_batch = np.append(x_batch[y_len:], new_y, axis=0)\n",
    "    \n",
    "    if (i % display_interval == 0):\n",
    "        print('Iteration: %g / %g, len(prediction) = %g / %g' % (i, num_predictions, len(prediction), orig_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "converted_original = music_data.convert_to_wav(original)\n",
    "converted_prediction = music_data.convert_to_wav(prediction)\n",
    "pred_len = converted_prediction.shape[0]\n",
    "x_orig = np.linspace(0, orig_len/music_data.sample_rate, orig_len)\n",
    "x_conv = np.linspace(0, pred_len/music_data.sample_rate, pred_len)\n",
    "plt.subplot(211)\n",
    "plt.plot(x_orig[0:300], converted_original[0:300])\n",
    "plt.subplot(212)\n",
    "plt.plot(x_conv[0:300], converted_prediction[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
